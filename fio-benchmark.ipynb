{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\"/>\n",
    "\n",
    "# TB - DevOps: Mise en place de cloud-native storage\n",
    "## fio benchmark\n",
    "**Note**: La version de fio utilisée pour chaque benchmark va être explicitement décrite tel que la license morale (section 4 [documentation](https://fio.readthedocs.io/en/latest/fio_doc.html#moral-license) fio) nous recommande."
   ]
  },
  {
   "source": [
    "Les tests se sont basés sur le benchmarking réalisé par Architecting-IT est accessible en [ligne](https://resources.storageos.com/downloadbenchmarkreport). Le benchmarking des différentes solutions ont réussi à démontré que StorageOs ressortait en tête parmi ses principaux concurrent en tant que solution de stockage block.\n",
    "\n",
    "Ce que l'on va tenter de montrer est les différentes options proposées par Longhorn, essayer de comprendre son fonctionnement interne et voir si cela se manifeste dans notre benchmarking. \n",
    "\n",
    "Dans la méthodologie de test, on va montrer les différents déploiements utilisés (ce qui n'est pas fait dans le rapport par Architecting-IT) et proposer un déploiement via une image, ce qui aidera à la reproductibilité des tests effectués. Architecting-IT a effectué ses tests manuellement pour les raisons suivantes:\n",
    "* To ensure that any lazy write process on file system creation didn’t affect the performance figures.\n",
    "* To permit the validation of the container<->volume mapping and check the volume was the requisite size.\n",
    "* To run iostat, top and iftop on each worker node. The output from these commands is not included but used to validate that there are no bottlenecks in CPU and network utilisation that could affect performance during test runs.\n",
    "\n",
    "TODO demander à Marcel Graf si c'est grave? Est-ce que je devrais moi aussi run iostat+top+iftop pour guarantir qu'il n'y ait pas de CPU ou network bottleneck? \n",
    "\n",
    "On souhaite explorer les différents paramètres que Longhorn offre et voir leurs impacts dans les performances. Le hardware utilisé étant différent, on peut s'attendre à des résultats différents."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test en Local\n",
    "Les résultats de cette section ont été généré à l'aide de fio version 3.16 à l'aide du script `run-all-jobs.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# from: https://stackoverflow.com/a/3207973\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "fio_jobs_path = 'fio-jobs-output/local'\n",
    "job_outputs_filename = [f for f in listdir(fio_jobs_path) if isfile(join(fio_jobs_path, f)) and 'output' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fio version': 'fio-3.16', 'timestamp': 1624716221, 'timestamp_ms': 1624716221209, 'time': 'Sat Jun 26 16:03:41 2021', 'global options': {'bs': '4K', 'iodepth': '256', 'direct': '1', 'ioengine': 'libaio', 'runtime': '120', 'numjobs': '4', 'size': '512M', 'name': 'raw-seqread', 'rw': 'read'}, 'jobs': [{'jobname': 'job1', 'groupid': 0, 'error': 0, 'eta': 0, 'elapsed': 121, 'job options': {'filename': '/dev/nvme0n1p7'}, 'read': {'io_bytes': 85691441152, 'io_kbytes': 83683048, 'bw_bytes': 714035839, 'bw': 697300, 'iops': 174325.156237, 'runtime': 120010, 'total_ios': 20920762, 'short_ios': 0, 'drop_ios': 0, 'slat_ns': {'min': 712, 'max': 318915, 'mean': 1345.356346, 'stddev': 891.144287}, 'clat_ns': {'min': 93938, 'max': 19756113, 'mean': 5872300.887986, 'stddev': 2146245.617705, 'percentile': {'1.000000': 1482752, '5.000000': 4014080, '10.000000': 4145152, '20.000000': 4227072, '30.000000': 4358144, '40.000000': 4489216, '50.000000': 5144576, '60.000000': 5406720, '70.000000': 7569408, '80.000000': 8028160, '90.000000': 9371648, '95.000000': 9895936, '99.000000': 11075584, '99.500000': 11599872, '99.900000': 12779520, '99.950000': 13303808, '99.990000': 14483456}}, 'lat_ns': {'min': 96030, 'max': 19757323, 'mean': 5873719.170813, 'stddev': 2146249.697853}, 'bw_min': 456392, 'bw_max': 940271, 'bw_agg': 99.999382, 'bw_mean': 697295.6875, 'bw_dev': 40813.563058, 'bw_samples': 960, 'iops_min': 114098, 'iops_max': 235067, 'iops_mean': 174323.904167, 'iops_stddev': 10203.391614, 'iops_samples': 960}, 'write': {'io_bytes': 0, 'io_kbytes': 0, 'bw_bytes': 0, 'bw': 0, 'iops': 0.0, 'runtime': 0, 'total_ios': 0, 'short_ios': 0, 'drop_ios': 0, 'slat_ns': {'min': 0, 'max': 0, 'mean': 0.0, 'stddev': 0.0}, 'clat_ns': {'min': 0, 'max': 0, 'mean': 0.0, 'stddev': 0.0, 'percentile': {'1.000000': 0, '5.000000': 0, '10.000000': 0, '20.000000': 0, '30.000000': 0, '40.000000': 0, '50.000000': 0, '60.000000': 0, '70.000000': 0, '80.000000': 0, '90.000000': 0, '95.000000': 0, '99.000000': 0, '99.500000': 0, '99.900000': 0, '99.950000': 0, '99.990000': 0}}, 'lat_ns': {'min': 0, 'max': 0, 'mean': 0.0, 'stddev': 0.0}, 'bw_min': 0, 'bw_max': 0, 'bw_agg': 0.0, 'bw_mean': 0.0, 'bw_dev': 0.0, 'bw_samples': 0, 'iops_min': 0, 'iops_max': 0, 'iops_mean': 0.0, 'iops_stddev': 0.0, 'iops_samples': 0}, 'trim': {'io_bytes': 0, 'io_kbytes': 0, 'bw_bytes': 0, 'bw': 0, 'iops': 0.0, 'runtime': 0, 'total_ios': 0, 'short_ios': 0, 'drop_ios': 0, 'slat_ns': {'min': 0, 'max': 0, 'mean': 0.0, 'stddev': 0.0}, 'clat_ns': {'min': 0, 'max': 0, 'mean': 0.0, 'stddev': 0.0, 'percentile': {'1.000000': 0, '5.000000': 0, '10.000000': 0, '20.000000': 0, '30.000000': 0, '40.000000': 0, '50.000000': 0, '60.000000': 0, '70.000000': 0, '80.000000': 0, '90.000000': 0, '95.000000': 0, '99.000000': 0, '99.500000': 0, '99.900000': 0, '99.950000': 0, '99.990000': 0}}, 'lat_ns': {'min': 0, 'max': 0, 'mean': 0.0, 'stddev': 0.0}, 'bw_min': 0, 'bw_max': 0, 'bw_agg': 0.0, 'bw_mean': 0.0, 'bw_dev': 0.0, 'bw_samples': 0, 'iops_min': 0, 'iops_max': 0, 'iops_mean': 0.0, 'iops_stddev': 0.0, 'iops_samples': 0}, 'sync': {'lat_ns': {'min': 0, 'max': 0, 'mean': 0.0, 'stddev': 0.0, 'percentile': {'1.000000': 0, '5.000000': 0, '10.000000': 0, '20.000000': 0, '30.000000': 0, '40.000000': 0, '50.000000': 0, '60.000000': 0, '70.000000': 0, '80.000000': 0, '90.000000': 0, '95.000000': 0, '99.000000': 0, '99.500000': 0, '99.900000': 0, '99.950000': 0, '99.990000': 0}}, 'total_ios': 0}, 'job_runtime': 480036, 'usr_cpu': 4.060945, 'sys_cpu': 11.02084, 'ctx': 17152966, 'majf': 0, 'minf': 1072, 'iodepth_level': {'1': 0.1, '2': 0.1, '4': 0.1, '8': 0.1, '16': 0.1, '32': 0.1, '>=64': 99.998795}, 'iodepth_submit': {'0': 0.0, '4': 100.0, '8': 0.0, '16': 0.0, '32': 0.0, '64': 0.0, '>=64': 0.0}, 'iodepth_complete': {'0': 0.0, '4': 99.999981, '8': 0.0, '16': 0.0, '32': 0.0, '64': 0.0, '>=64': 0.1}, 'latency_ns': {'2': 0.0, '4': 0.0, '10': 0.0, '20': 0.0, '50': 0.0, '100': 0.0, '250': 0.0, '500': 0.0, '750': 0.0, '1000': 0.0}, 'latency_us': {'2': 0.0, '4': 0.0, '10': 0.0, '20': 0.0, '50': 0.0, '100': 0.01, '250': 0.01, '500': 0.145133, '750': 0.208033, '1000': 0.217177}, 'latency_ms': {'2': 0.945821, '4': 3.353353, '10': 91.070937, '20': 4.055254, '50': 0.0, '100': 0.0, '250': 0.0, '500': 0.0, '750': 0.0, '1000': 0.0, '2000': 0.0, '>=2000': 0.0}, 'latency_depth': 256, 'latency_target': 0, 'latency_percentile': 100.0, 'latency_window': 0}], 'disk_util': [{'name': 'nvme0n1', 'read_ios': 20907495, 'write_ios': 60, 'read_merges': 0, 'write_merges': 49, 'read_ticks': 122710597, 'write_ticks': 239, 'in_queue': 122710868, 'util': 99.967487}]}\n"
     ]
    }
   ],
   "source": [
    "job_outputs = []\n",
    "\n",
    "# Load the results\n",
    "for job_output in job_outputs_filename:\n",
    "    f = open(f\"{fio_jobs_path}/{job_output}\")\n",
    "    data = json.load(f)\n",
    "    job_outputs.append(data)\n",
    "\n",
    "print(job_outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test sur le cluster IICT\n",
    "On souhaite déployer un container docker avec un PV dans le cluster IICT. Le container contient l'outil *fio* et un dossier *fio-jobs*.\n",
    "\n",
    "Architecting-it a fait des [scripts](https://github.com/architectingit/k8sstorage/blob/main/perfraw.sh) pour réaliser ses tests. On va s'inspirer de leur script pour réaliser nos tests.\n",
    "\n",
    "<u>**Connection au cluster IICT**</u>\n",
    "\n",
    "Connectez-vous au VPN de l'école:\n",
    "```bash\n",
    "$ kubectl config get-contexts         # is ` iict ` listed ?\n",
    "$ kubectl config use-context iict\n",
    "```\n",
    "\n",
    "<u>**Infrastructure testée**</u>\n",
    "\n",
    "TODO mail à Rémi"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Benchmarking à la main\n",
    "Si vous désirer allez plus rapidement, sautez à la section suivante (on applique une configuration dans le cluster et récupère les résultats):\n",
    "\n",
    "<u>**Déploiement**</u>\n",
    "\n",
    "```bash\n",
    "$ kubectl apply -f iict-fio-benchmark-manual.yaml\n",
    "```\n",
    "\n",
    "Observons quel classe de stockage sont disponibles :\n",
    "```bash\n",
    "$ kubectl get storageclass\n",
    "NAME                 PROVISIONER                                     RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
    "longhorn (default)   driver.longhorn.io                              Delete          Immediate           true                   170d\n",
    "nfs-client           cluster.local/nfs-subdir-external-provisioner   Delete          Immediate           true                   114d\n",
    "```\n",
    "\n",
    "Nous allons donc utiliser un PVC de storageclass `longhorn`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<u>**Exécution des tests**</u>\n",
    "\n",
    "Ensuite, on déploie un container simple:\n",
    "\n",
    "```bash\n",
    "$ kubectl apply --namespace=mercado -f iict-fio-benchmark-manual.yaml\n",
    "```\n",
    "\n",
    "On vérifie que le container a bien démarré:\n",
    "```bash\n",
    "$ kubectl get pods --namespace=mercado\n",
    "```\n",
    "\n",
    "On ouvre une session interactive et on install fio:\n",
    "```bash\n",
    "$ kubectl exec --namespace=mercado -it $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}') -- /bin/sh\n",
    "/ # apk add fio\n",
    "/ # fio --version\n",
    "$ exit # on sort de la session\n",
    "```\n",
    "\n",
    "On va copier un fio-job et un script permettant de run tous les tests:\n",
    "```bash\n",
    "# copy test script to pod\n",
    "$ kubectl --namespace=mercado cp docker/iict/run-all-jobs.sh $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "\n",
    "# copy all jobs to pod\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/random-read.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/random-readwrite.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/random-write.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/sequential-read.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/sequential-readwrite.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/sequential-write.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "```\n",
    "\n",
    "Et on exécute les tests:\n",
    "```bash\n",
    "# ouvrir une session interactive\n",
    "$ kubectl exec --namespace=mercado -it $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}') -- /bin/sh\n",
    "/ # sh run-all-jobs.sh\n",
    "/ # exit\n",
    "```\n",
    "\n",
    "On récupère tous les outputs:\n",
    "```shell\n",
    "$ kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/random-read.fio-output fio-jobs/iict/random-read.fio-output\n",
    "$ kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/random-readwrite.fio-output fio-jobs/iict/random-readwrite.fio-output\n",
    "$ kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/random-write.fio-output fio-jobs/iict/random-write.fio-output\n",
    "$ kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/sequential-read.fio-output fio-jobs/iict/sequential-read.fio-output\n",
    "$ kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/sequential-readwrite.fio-output fio-jobs/iict/sequential-readwrite.fio-output\n",
    "$ kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/sequential-write.fio-output fio-jobs/iict/sequential-write.fio-output\n",
    "```\n",
    "\n",
    "Une fois que l'on a terminé, on nettoie:\n",
    "```bash\n",
    "kubectl delete -f iict-fio-benchmark-manual.yaml\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Image\n",
    "\n",
    "Nous allons déployer une image contenant les scripts de tests et un script d'exécution des tests en quelques lignes. On déploie :\n",
    "\n",
    "```bash\n",
    "$ kubectl apply -f iict-fio-benchmark.yaml\n",
    "```\n",
    "\n",
    "On peut observer l'exécution du container en consultant les logs (ou en allant sur l'UI rancher qui se rafraîchit automatiquement):\n",
    "```bash\n",
    "$ kubectl logs --follow $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}') --namespace=mercado\n",
    "```\n",
    "\n",
    "Une fois que les logs affiche `\"All jobs done\"`, alors on peut récupérer les output et nettoyer les ressources:\n",
    "\n",
    "```bash\n",
    "$ sh iict-fio-benchmark-get-output.sh\n",
    "$ kubectl delete -f iict-fio-benchmark.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Maintenant on va visualiser nos données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from: https://stackoverflow.com/a/3207973\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "fio_jobs_path = 'docker/iict/fio-jobs'\n",
    "job_outputs_filename = [f for f in listdir(fio_jobs_path) if isfile(join(fio_jobs_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fio-jobs-output/iict/deployment-01-???/architecting-it-test8-sequential-write-output'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-5738d641aa7e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# Load the results\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mjob_output\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mjob_outputs_filename\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"fio-jobs-output/iict/deployment-01-???/{job_output}-output\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mjob_outputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'fio-jobs-output/iict/deployment-01-???/architecting-it-test8-sequential-write-output'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "job_outputs = []\n",
    "\n",
    "# Load the results\n",
    "for job_output in job_outputs_filename:\n",
    "    f = open(f\"fio-jobs-output/iict/deployment-01-???/{job_output}-output\")\n",
    "    data = json.load(f)\n",
    "    job_outputs.append(data)\n",
    "\n",
    "print(job_outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Déploiement d'une nouvelle image\n",
    "\n",
    "Pour mettre à jour l'image que le cluster peut utiliser pour benchmark (avec de nouveaux scénarios de tests ou des modifications), on tag un commit de ce repository avec, par exemple :\n",
    "\n",
    "```bash\n",
    "$ git tag # what tag can we use?\n",
    "...\n",
    "v0.1.4\n",
    "v0.1.5\n",
    "v0.1.6\n",
    "v0.1.7\n",
    "\n",
    "$ git tag v0.1.8\n",
    "$ git push origin tag v0.1.8\n",
    "```\n",
    "\n",
    "On patiente un moment que l'image soit mise en ligne puis on peut réaliser notre benchmark.\n",
    "\n",
    "**Note**: La github Action ne build que les images en `v0.*.*` pour le moment."
   ]
  },
  {
   "source": [
    "# Traîtement de l'output\n",
    "En s'inspirant des 9 jobs fait par Architecting-IT, on va extraire les résultats:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deployment_output_folder_path(is_iict: bool, idx: int):\n",
    "    \"\"\"\n",
    "    :param is_iict: true if the deployment is related to IICT\n",
    "    :param idx: the deployment\n",
    "    :return: the deployment folder path\n",
    "    \"\"\"\n",
    "    folder = \"local\"\n",
    "    if is_iict:\n",
    "        folder = \"iict\"\n",
    "\n",
    "    return f\"fio-jobs-output/{folder}/deployment-{idx:02d}-???\"\n",
    "\n",
    "print(deployment_output_folder_path(is_iict=True, idx=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def deployment_output(deployment_output_folder: str):\n",
    "    \"\"\"\n",
    "    :param deployment_output_folder:\n",
    "    :return: a filtered view of all jobs with relevant metrics\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    for f in listdir(deployment_output_folder):\n",
    "        print(f)\n",
    "        o = json.load(open(f\"{deployment_output_folder}/{f}\"))\n",
    "        if o['global options']['name'] == 'read_iops':\n",
    "            # TODO parse\n",
    "            output['read_seq'] = o\n",
    "        if o['global options']['name'] == 'write_iops':\n",
    "            # TODO parse\n",
    "            output['read_seq'] = o\n",
    "        if o['global options']['name'] == 'read_bw':\n",
    "            # TODO verify\n",
    "            output['read_bw'] = o['jobs'][0]['read']['bw_mean']\n",
    "        if o['global options']['name'] == 'write_bw':\n",
    "            # TODO parse\n",
    "            output['read_seq'] = o\n",
    "        if o['global options']['name'] == 'read_latency':\n",
    "            # TODO parse\n",
    "            output['read_seq'] = o\n",
    "        if o['global options']['name'] == 'write_latency':\n",
    "            # TODO parse\n",
    "            output['read_seq'] = o\n",
    "        if o['global options']['name'] == 'seq_read':\n",
    "            # TODO parse\n",
    "            output['read_seq'] = o\n",
    "        if o['global options']['name'] == 'seq_write':\n",
    "            # TODO parse\n",
    "            output['read_seq'] = o\n",
    "        if o['global options']['name'] == 'rw_mix':\n",
    "            # TODO parse\n",
    "            output['read_seq'] = o\n",
    "    return output\n",
    "\n",
    "print(deployment_output(deployment_output_folder_path(True, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Configuration de Longhorn testée\n",
    "* replicas\n",
    "* data locality\n",
    "* scheduling policy?\n",
    "* volumeMode\n",
    "\n",
    "[I/O operations and replicas](https://longhorn.io/docs/1.1.1/concepts/#231-how-read-and-write-operations-work-for-replicas)\n",
    "\n",
    "Dans un volume Longhorn, lorsque les opérations I/O sont faites sur une replica, ces opérations se font d'abord sur le live data. Si le bloc cherché n'est pas sur le live data, alors, il va cherché le bloc dans la snapshot la plus récente jusqu'à ce qu'il trouve la bonne snapshot. Une fois trouvé, un index est conservé pour se souvenir de la snapshot la plus récente contenant le bloc recherché.\n",
    "\n",
    "L'index est conservé en mémoire et a une taille de 1 byte par block de taille 4K.\n",
    "\n",
    "[taille effective des volumes/replicas/snapshot](https://longhorn.io/docs/1.1.1/volumes-and-nodes/volume-size/#an-example-that-helps-understand-volume-size-and-volume-actual-size)\n",
    "\n",
    "Au départ, les volumes ne prennent pas de places. Mais après qu'un document soit supprimé du FS dans le volume, cela n'est pas répliqué au niveau bloc: *\"The truth of the data#1 deletion is that the data#1 is marked as removed in the filesystem level (For example, inode deletion in ext4). Since Longhorn operates on the block level and does not understand the filesystem, as a result, the disk blocks/space storing data#1 won’t be released after the deletion.\"*\n",
    "\n",
    "Est-ce que ce serait intéressant de démontrer ça?\n",
    "\n",
    "[Longhorn engine par volume](https://longhorn.io/docs/1.1.1/concepts/#11-the-longhorn-manager-and-the-longhorn-engine)\n",
    "\n",
    "Super intéressant.\n",
    "\n",
    "[replica par défaut](https://longhorn.io/docs/1.1.1/references/settings/#default-replica-count)\n",
    "\n",
    "3 apparament??? Est-ce que je peux le vérifier moi-même?\n",
    "\n",
    "[volumeMode block](https://longhorn.io/docs/0.8.0/examples/block-volume/)\n",
    "\n",
    "what is this\n",
    "\n",
    "[PV avec csi option, numberofreplicas](https://longhorn.io/docs/0.8.0/examples/csi-pv/)\n",
    "\n",
    "[volumeMode: Filesystem](https://github.com/longhorn/longhorn/blob/8318d99136e0d5b39f01a37adf9cae5342034d7e/examples/csi/example_pv.yaml#L8)\n",
    "\n",
    "[persistentVolumeReclaimPolicy: Delete](https://github.com/longhorn/longhorn/blob/8318d99136e0d5b39f01a37adf9cae5342034d7e/examples/csi/example_pv.yaml#L11)\n",
    "\n",
    "\n",
    "Note: [google](https://cloud.google.com/compute/docs/disks/benchmarking-pd-performance) persistent disk benchmark"
   ]
  },
  {
   "source": [
    "## Volume mode\n",
    "\n",
    "[volume mode](https://longhorn.io/docs/0.8.0/install/customizing-default-settings/#via-longhorn-deployment-yaml-file)\n",
    "\n",
    "* filesystem (défaut)\n",
    "* block\n",
    "\n",
    "Le type de volume [block](https://kubernetes.io/blog/2019/03/07/raw-block-volume-support-to-beta/#why-add-raw-block-volumes-to-kubernetes) est pour les applications spécialisées. Benchmarker un volume de ce type mène à une erreur ('Not a directory'). Est-ce possible de tester un raw block device avec fio ?\n",
    "\n",
    "TODO chercher si raw block device test est possible"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Nombre de replicas\n",
    "\n",
    "Par défaut, le nombre de replicas est de 3 tel que montré:\n",
    "\n",
    "![idk](img/default-pvc-replicas.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "source": [
    "On va tester les performances lorsqu'il y a 0, 1, 3 (par défaut) et 5 replicas (deployment-03-06).\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = deployment_output(deployment_output_folder_path(True, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "## Remote ou local PV\n",
    "\n",
    "On va tenter de faire un deployment avec le container dans un noeud et le pv dans le même.\n",
    "Puis on va faire tester lorsque le container et le PV sont dans des nodes séparés.\n",
    "\n",
    "On utilise le node-selector pour grouper/séparer le container et le pv.\n",
    "\n",
    "Les nodes disponibles sur le cluster sont:\n",
    "```bash\n",
    "$ kubectl get nodes\n",
    "NAME           STATUS   ROLES                      AGE    VERSION\n",
    "10.193.72.32   Ready    controlplane,etcd,worker   196d   v1.19.3\n",
    "10.193.72.33   Ready    worker                     196d   v1.19.3\n",
    "10.193.72.34   Ready    worker                     176d   v1.19.3\n",
    "```\n",
    "\n",
    "On a donc les différentes addresses IP comme noms.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "72cb84ee8889e4f5449c4efd23c39e13f10da0b153d3918057aa0634ac1d69f8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}