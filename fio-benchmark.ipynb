{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\"/>\n",
    "\n",
    "# TB - DevOps: Mise en place de cloud-native storage\n",
    "## fio benchmark\n",
    "**Note**: La version de fio utilisée pour chaque benchmark va être explicitement décrite tel que la license morale (section 4 [documentation](https://fio.readthedocs.io/en/latest/fio_doc.html#moral-license) fio) nous recommande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Local\n",
    "Les résultats de cette section ont été généré à l'aide de fio version 3.16 à l'aide du script `run-all-jobs.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fio-jobs/local'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-23d681b86acb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mfio_jobs_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'fio-jobs/local'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mjob_outputs_filename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mf\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlistdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfio_jobs_path\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0misfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfio_jobs_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m'output'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'fio-jobs/local'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# from: https://stackoverflow.com/a/3207973\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "fio_jobs_path = 'fio-jobs/local'\n",
    "job_outputs_filename = [f for f in listdir(fio_jobs_path) if isfile(join(fio_jobs_path, f)) and 'output' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "job_outputs = []\n",
    "\n",
    "# Load the results\n",
    "for job_output in job_outputs_filename:\n",
    "    f = open(f\"{fio_jobs_path}/{job_output}\")\n",
    "    data = json.load(f)\n",
    "    job_outputs.append(data)\n",
    "\n",
    "print(job_outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cluster IICT\n",
    "On souhaite déployer un container docker avec un PV dans le cluster IICT. Le container contient l'outil *fio* et un dossier *fio-jobs*.\n",
    "\n",
    "Architecting-it a fait des [scripts](https://github.com/architectingit/k8sstorage/blob/main/perfraw.sh) pour réaliser ses tests. On va s'inspirer de leur script pour réaliser nos tests.\n",
    "### Benchmarking\n",
    "#### Connection au cluster IICT\n",
    "Connectez-vous au VPN de l'école, puis:\n",
    "```bash\n",
    "kubectl config get-contexts         # is ` iict ` listed ?\n",
    "kubectl config use-context iict\n",
    "```\n",
    "\n",
    "#### Manual\n",
    "Si vous désirer allez plus rapidement, sautez à la section suivante (on applique une configuration dans le cluster et récupère les résultats):\n",
    "\n",
    "```bash\n",
    "kubectl apply -f iict-fio-benchmark-manual.yaml\n",
    "```\n",
    "\n",
    "Observons quel classe de stockage sont disponibles :\n",
    "```bash\n",
    "$ kubectl get storageclass\n",
    "NAME                 PROVISIONER                                     RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\n",
    "longhorn (default)   driver.longhorn.io                              Delete          Immediate           true                   170d\n",
    "nfs-client           cluster.local/nfs-subdir-external-provisioner   Delete          Immediate           true                   114d\n",
    "```\n",
    "\n",
    "Nous allons donc utiliser un PVC de storageclass `longhorn`.\n",
    "\n",
    "Ensuite, on déploie un container simple:\n",
    "\n",
    "```bash\n",
    "$ kubectl apply --namespace=mercado -f iict-fio-benchmark-manual.yaml\n",
    "```\n",
    "\n",
    "On vérifie que le container a bien démarré:\n",
    "```bash\n",
    "$ kubectl get pods --namespace=mercado\n",
    "```\n",
    "\n",
    "On ouvre une session interactive et on install fio:\n",
    "```bash\n",
    "$ kubectl exec --namespace=mercado -it $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}') -- /bin/sh\n",
    "/ # apk add fio\n",
    "/ # fio --version\n",
    "$ exit # on sort de la session\n",
    "```\n",
    "\n",
    "On va copier un fio-job et un script permettant de run tous les tests:\n",
    "```bash\n",
    "# copy test script\n",
    "$ kubectl --namespace=mercado cp docker/iict/run-all-jobs.sh $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "\n",
    "# copy all jobs\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/random-read.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/random-readwrite.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/random-write.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/sequential-read.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/sequential-readwrite.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "$ kubectl --namespace=mercado cp docker/iict/fio-jobs/sequential-write.fio $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/\n",
    "```\n",
    "\n",
    "Et on exécute les tests:\n",
    "```bash\n",
    "# ouvrir une session interactive\n",
    "kubectl exec --namespace=mercado -it $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}') -- /bin/sh\n",
    "sh run-all-jobs.sh\n",
    "exit\n",
    "```\n",
    "\n",
    "On récupère tous les outputs:\n",
    "```bash\n",
    "kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/random-read.fio-output fio-jobs/iict/random-read.fio-output\n",
    "kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/random-readwrite.fio-output fio-jobs/iict/random-readwrite.fio-output\n",
    "kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/random-write.fio-output fio-jobs/iict/random-write.fio-output\n",
    "kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/sequential-read.fio-output fio-jobs/iict/sequential-read.fio-output\n",
    "kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/sequential-readwrite.fio-output fio-jobs/iict/sequential-readwrite.fio-output\n",
    "kubectl --namespace=mercado cp $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}'):/sequential-write.fio-output fio-jobs/iict/sequential-write.fio-output\n",
    "```\n",
    "\n",
    "Une fois que l'on a terminé, on nettoie:\n",
    "```bash\n",
    "kubectl delete -f iict-fio-benchmark-manual.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Image\n",
    "\n",
    "Nous allons déployer une image contenant les scripts de tests et un script d'exécution des tests en quelques lignes. On déploie :\n",
    "\n",
    "```bash\n",
    "$ kubectl apply -f iict-fio-benchmark.yaml\n",
    "```\n",
    "\n",
    "On peut observer l'exécution du container en consultant les logs (ou en allant sur l'UI rancher qui se rafraîchit automatiquement):\n",
    "```bash\n",
    "$ kubectl logs --follow $(kubectl get pods --namespace=mercado -o=jsonpath='{.items[0].metadata.name}') --namespace=mercado\n",
    "```\n",
    "\n",
    "Une fois que les logs affiche `\"All jobs done\"`, alors on peut récupérer les output et nettoyer les ressources:\n",
    "\n",
    "```bash\n",
    "$ sh iict-fio-benchmark-get-output.sh\n",
    "$ kubectl delete -f iict-fio-benchmark.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Maintenant on va visualiser nos données:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from: https://stackoverflow.com/a/3207973\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "fio_jobs_path = 'docker/iict/fio-jobs'\n",
    "job_outputs_filename = [f for f in listdir(fio_jobs_path) if isfile(join(fio_jobs_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "job_outputs = []\n",
    "\n",
    "# Load the results\n",
    "for job_output in job_outputs_filename:\n",
    "    f = open(f\"fio-jobs/iict/{job_output}-output\")\n",
    "    data = json.load(f)\n",
    "    job_outputs.append(data)\n",
    "\n",
    "print(job_outputs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note: [google](https://cloud.google.com/compute/docs/disks/benchmarking-pd-performance) persistent disk benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Déploiement d'une nouvelle image\n",
    "\n",
    "Pour mettre à jour l'image que le cluster peut utiliser pour benchmark (avec de nouveaux scénarios de tests ou des modifications), on tag un commit de ce repository avec, par exemple :\n",
    "\n",
    "```bash\n",
    "$ git tag # what tag can we use?\n",
    "...\n",
    "v0.1.4\n",
    "v0.1.5\n",
    "v0.1.6\n",
    "v0.1.7\n",
    "\n",
    "$ git tag v0.1.8\n",
    "$ git push origin tag v0.1.8\n",
    "```\n",
    "\n",
    "On patiente un moment que l'image soit mise en ligne puis on peut réaliser notre benchmark.\n",
    "\n",
    "**Note**: La github Action ne build que les images en `v0.*.*` pour le moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configuration de Longhorn a tester\n",
    "* replicas\n",
    "* data locality\n",
    "* scheduling policy?\n",
    "\n",
    "[I/O operations and replicas](https://longhorn.io/docs/1.1.1/concepts/#231-how-read-and-write-operations-work-for-replicas)\n",
    "\n",
    "Dans un volume Longhorn, lorsque les opérations I/O sont faites sur une replica, ces opérations se font d'abord sur le live data. Si le bloc cherché n'est pas sur le live data, alors, il va cherché le bloc dans la snapshot la plus récente jusqu'à ce qu'il trouve la bonne snapshot. Une fois trouvé, un index est conservé pour se souvenir de la snapshot la plus récente contenant le bloc recherché.\n",
    "\n",
    "L'index est conservé en mémoire et a une taille de 1 byte par block de taille 4K.\n",
    "\n",
    "[taille effective des volumes/replicas/snapshot](https://longhorn.io/docs/1.1.1/volumes-and-nodes/volume-size/#an-example-that-helps-understand-volume-size-and-volume-actual-size)\n",
    "\n",
    "Au départ, les volumes ne prennent pas de places. Mais après qu'un document soit supprimé du FS dans le volume, cela n'est pas répliqué au niveau bloc: *\"The truth of the data#1 deletion is that the data#1 is marked as removed in the filesystem level (For example, inode deletion in ext4). Since Longhorn operates on the block level and does not understand the filesystem, as a result, the disk blocks/space storing data#1 won’t be released after the deletion.\"*\n",
    "\n",
    "Est-ce que ce serait intéressant de démontrer ça?\n",
    "\n",
    "[Longhorn engine par volume](https://longhorn.io/docs/1.1.1/concepts/#11-the-longhorn-manager-and-the-longhorn-engine)\n",
    "\n",
    "Super intéressant.\n",
    "\n",
    "[replica par défaut](https://longhorn.io/docs/1.1.1/references/settings/#default-replica-count)\n",
    "\n",
    "3 apparament??? Est-ce que je peux le vérifier moi-même?\n",
    "\n",
    "[volumeMode block](https://longhorn.io/docs/0.8.0/examples/block-volume/)\n",
    "\n",
    "what is this\n",
    "\n",
    "[PV avec csi option, numberofreplicas](https://longhorn.io/docs/0.8.0/examples/csi-pv/)\n",
    "\n",
    "[volumeMode: Filesystem](https://github.com/longhorn/longhorn/blob/8318d99136e0d5b39f01a37adf9cae5342034d7e/examples/csi/example_pv.yaml#L8)\n",
    "\n",
    "[persistentVolumeReclaimPolicy: Delete](https://github.com/longhorn/longhorn/blob/8318d99136e0d5b39f01a37adf9cae5342034d7e/examples/csi/example_pv.yaml#L11)\n",
    "\n",
    "[volume mode](https://longhorn.io/docs/0.8.0/install/customizing-default-settings/#via-longhorn-deployment-yaml-file)\n",
    "\n",
    "* filesystem (défaut)\n",
    "* block\n",
    "\n",
    "![Default replicas](/img/default-pvc-replicas.png)\n",
    "3 replicas par défaut\n",
    "\n",
    "Le type de volume [block](https://kubernetes.io/blog/2019/03/07/raw-block-volume-support-to-beta/#why-add-raw-block-volumes-to-kubernetes) est pour les applications spécialisées. Benchmarker un volume de ce type mène à une erreur ('Not a directory'). Est-ce possible de tester un raw block device avec fio ?\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}